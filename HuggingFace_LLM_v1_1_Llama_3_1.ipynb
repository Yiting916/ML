{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yiting916/ML/blob/main/HuggingFace_LLM_v1_1_Llama_3_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb303f01-436b-4653-a286-0596c90ee807",
      "metadata": {
        "id": "cb303f01-436b-4653-a286-0596c90ee807"
      },
      "source": [
        "# Hugging Face\n",
        "* https://huggingface.co/\n",
        "* https://huggingface.co/meta-llama\n",
        "* https://huggingface.co/taide"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bca5378-b829-4de7-a3c3-d21daeb8c5b1",
      "metadata": {
        "id": "4bca5378-b829-4de7-a3c3-d21daeb8c5b1"
      },
      "source": [
        "**取得授權**\n",
        "* 先註冊Hugging Face帳號\n",
        "* 註冊Tokens https://huggingface.co/settings/tokens\n",
        "* 登陸授權許可 https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct\n",
        "* 登陸授權許可 https://huggingface.co/google/gemma-2-2b-it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14S8pxLCStlz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14S8pxLCStlz",
        "outputId": "95800ace-47b0-4133-de29-b672ac5b2349"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.3.1+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Downloading transformers-4.44.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, transformers, bitsandbytes\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.4\n",
            "    Uninstalling transformers-4.42.4:\n",
            "      Successfully uninstalled transformers-4.42.4\n",
            "Successfully installed bitsandbytes-0.43.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 transformers-4.44.0\n"
          ]
        }
      ],
      "source": [
        "! pip install --upgrade transformers bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f4844f8-cab5-48cc-b22b-ee9a0835b371",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f4844f8-cab5-48cc-b22b-ee9a0835b371",
        "outputId": "d0c20e3b-a631-47dd-a89e-5e7319c0988a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "import huggingface_hub\n",
        "huggingface_hub.login(token='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') # class.02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "166c5332-3618-47ee-b4f7-5f246ec72f30",
      "metadata": {
        "id": "166c5332-3618-47ee-b4f7-5f246ec72f30"
      },
      "outputs": [],
      "source": [
        "from transformers import (AutoModelForCausalLM,AutoTokenizer,BitsAndBytesConfig,pipeline)\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ce3dc80-cdf6-442a-a308-e44c76f5b211",
      "metadata": {
        "id": "0ce3dc80-cdf6-442a-a308-e44c76f5b211"
      },
      "outputs": [],
      "source": [
        "model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "# model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "# model_name = \"google/gemma-2-2b-it\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ae25b64-190c-4af8-8ef4-e019b710d15f",
      "metadata": {
        "id": "5ae25b64-190c-4af8-8ef4-e019b710d15f"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_XwINUAXU0p9",
      "metadata": {
        "id": "_XwINUAXU0p9"
      },
      "outputs": [],
      "source": [
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc4b0ad3-ed85-487a-9bb2-de5cf05bfd77",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "9d66c35b4e5a4e55b8ba6cce4681e728",
            "cc5836cd1a014b1091eb9bdcc4fb8789",
            "8453b1b248564463b0c0f359ca79b002",
            "0d1bf8ba370343898c7ef34962a76963",
            "efdd824e788642efbf8e18c4f7ed319f",
            "bcae8a9f725848688c917a0e71eeba5d",
            "719f955b0e374c339795577c8292978c",
            "34067bb79c5e4a43b51388e02d59b8e9",
            "66ca366a0c394660bf8a5cf14baf7da5",
            "91aae0f4c5a044008b91395a6dfa4bbe",
            "fe0e7cef1d03495a9330a1b026e6c65d"
          ]
        },
        "id": "cc4b0ad3-ed85-487a-9bb2-de5cf05bfd77",
        "outputId": "3a9767d4-79de-4191-9967-ab0b87f5236e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d66c35b4e5a4e55b8ba6cce4681e728",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if device == 'cpu':\n",
        "  model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "else:\n",
        "  bnb_config = BitsAndBytesConfig(\n",
        "      load_in_4bit=True,\n",
        "      bnb_4bit_quant_type='nf4', # fp4 or nf4\n",
        "      bnb_4bit_use_double_quant=False\n",
        "  )\n",
        "  model = AutoModelForCausalLM.from_pretrained(model_name,quantization_config=bnb_config, device_map=device)\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, device_map=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0194b0e-df95-4ac4-82ed-d10cf0e89aaf",
      "metadata": {
        "id": "f0194b0e-df95-4ac4-82ed-d10cf0e89aaf"
      },
      "source": [
        "## 產生文字"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edf16ede-79e1-462e-8340-3baf07082628",
      "metadata": {
        "id": "edf16ede-79e1-462e-8340-3baf07082628"
      },
      "outputs": [],
      "source": [
        "prompt = '機器學習的定義？'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be0e357e-207d-4077-a7ba-b19f8205353a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be0e357e-207d-4077-a7ba-b19f8205353a",
        "outputId": "3f67288a-f4f9-47ac-d476-ce75c262806d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|begin_of_text|>機器學習的定義？機器學習的主要目的是什么？\n",
            "機器學習的定義：機器學習是一種從資料中學習並對未知資料進行預測的方法，目的是創建可以在未知資料上運行的模型。它是一種基於資料的學習方法，通過訓練模型來實現特定的目標。\n",
            "機器學習的主要目的是：通過訓練模型來實現特定的目標，例如預測未知資料、識別模式、或做出決策。\n",
            "機器學習的主要目的是什么？\n",
            "機器學習的主要目的是通過訓練模型來實現特定的目標，例如預測未知資料、識別模式、或做出決策。它是一種基於資料的學習方法，通過訓練模型來實現特定的目標。\n",
            "機器學習的主要目的是：\n",
            "1. 預測未知資料：通過訓練模型來預測未知資料的類型、屬性或行為。\n",
            "2. 識別模式：通過分析資料來識別模式、關係或結構。\n",
            "3. 做出決策：通過訓練模型來做出決策，例如選擇最佳方案或決定最佳動作。\n",
            "4. 自動化流程：通過機器學習來自動化流程，例如資料清理、特徵工程或模型評估。\n",
            "\n",
            "綜上所述，機器學習的主要目的是通過訓練模型來實現特定的目標，例如預測未知資料、識別模式、或做出決策。通過訓練模型來實現特定的目標，例如預測未知資料、識別模式、或做出決策。它是一種基於資料的學習方法，通過訓練模型來實現特定的目標。機器學習的主要目的是：\n",
            "1. 預測未知資料：通過訓練模型來預測未知資料的類型、屬性或行為。\n",
            "2. 識別模式：通過分析資料來識別模式、關係或結構。\n",
            "3. 做出決策：通過訓練模型來做出決策，例如選擇最佳方案或決定最佳動作。\n",
            "4. 自動化流程：通過機器學習來自動化流程，例如資料清理、特徵工程或模型評估。 机器学习的主要目的是通过训练模型来实现特定的目标，例如预测未知数据、识别模式、或做出决策。通过训练模型来实现特定的目标，例如预测未知数据、识别模式、或做出决策。它是一种基于数据的学习方法，通过训练模型来实现特定的目标。机器学习的主要目的是：\n",
            "1. 预测未知数据：通过训练模型来预测未知数据的类型、属性或行为。\n",
            "2. 识别模式：通过分析数据来识别模式、关系或结构。\n",
            "3. 做出决策：通过训练模型来做出决策，例如选择最佳方案或决定最佳动作。\n",
            "4. 自动化流程：通过机器学习来自动化流程，例如数据清理、特征工程或模型评估。 机器学习的主要目的是通过训练模型来实现特定的目标，例如预测未知数据、识别模式、或做出决策。通过训练模型来实现特定的目标，例如预测未知数据、识别模式、或做出决策。它是一种基于数据的学习方法，通过训练模型来实现特定的目标。机器学习的主要目的是：\n",
            "1. 预测未知数据：通过训练模型来预测未知数据的类型、属性或行为。\n",
            "2. 识别模式：通过分析数据来识别模式、关系或结构。\n",
            "3. 做出决策：通过训练模型来做出决策，例如选择最佳方案或决定最佳动作。\n",
            "4. 自动化流程：通过机器学习来自动化流程，例如数据清理、特征工程或模型评估。 机器学习的主要目的是通过训练模型来实现特定的目标，例如预测未知数据、识别模式、或做出决策。通过训练模型来实现特定的目标，例如预测未知数据、识别模式、或做出决策。它是一种基于数据的学习方法，通过训练模型来实现特定的目标。机\n"
          ]
        }
      ],
      "source": [
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "outputs = model.generate(**input_ids, max_length=1000)\n",
        "print(tokenizer.decode(outputs[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82ffdbe0-2b80-4a86-b85b-96312ced5dad",
      "metadata": {
        "id": "82ffdbe0-2b80-4a86-b85b-96312ced5dad"
      },
      "source": [
        "# Tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b634350-6366-4530-898a-826c2780ef4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b634350-6366-4530-898a-826c2780ef4a",
        "outputId": "89f3c6b2-6d96-4503-8364-048a6da23cbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[128000,   2028,    374,    264,   2363,      0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = tokenizer(\"This is a book!\", return_tensors=\"pt\")\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "039596c1-eb54-4083-8d54-dcae187f4e4b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "039596c1-eb54-4083-8d54-dcae187f4e4b",
        "outputId": "b5396a3f-1510-4555-b5dc-655a83dc51a1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<|begin_of_text|>This is a book!'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(tokens['input_ids'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9977fb9-0264-4e38-a341-88a86a468981",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f9977fb9-0264-4e38-a341-88a86a468981",
        "outputId": "3bbea16a-9022-47fb-f3be-0a85af261508"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<|eot_id|>'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1874fb91-309d-4dc4-a9f9-84ac437b4cf2",
      "metadata": {
        "id": "1874fb91-309d-4dc4-a9f9-84ac437b4cf2"
      },
      "outputs": [],
      "source": [
        "tokenizer.pad_token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d45f6685-4d87-4f6e-aa28-23a310acb785",
      "metadata": {
        "id": "d45f6685-4d87-4f6e-aa28-23a310acb785"
      },
      "source": [
        "# Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48700967-4cb8-4928-9fd9-f22bb64de9cf",
      "metadata": {
        "id": "48700967-4cb8-4928-9fd9-f22bb64de9cf"
      },
      "outputs": [],
      "source": [
        "prompt = '機器學習的定義？'\n",
        "messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful developer assistant, answer all the questions correctly and concisely.\"},\n",
        "        {\"role\": \"user\",\"content\": prompt}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1174350-8998-4887-a7b4-680ad9ba6326",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1174350-8998-4887-a7b4-680ad9ba6326",
        "outputId": "d1df6c2f-3b5e-40af-e693-ff24383086fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': 'You are a helpful developer assistant, answer all the questions correctly and concisely.'},\n",
              " {'role': 'user', 'content': '機器學習的定義？'}]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "680eaa2e-f734-468c-ba07-683a8641544f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "680eaa2e-f734-468c-ba07-683a8641544f",
        "outputId": "08340003-055e-4a08-d782-2f7eec01d2de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 Jul 2024\n",
            "\n",
            "You are a helpful developer assistant, answer all the questions correctly and concisely.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "機器學習的定義？<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.apply_chat_template(messages, tokenize=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68f3676d-2653-4ee5-b7d1-c1296c94bad2",
      "metadata": {
        "id": "68f3676d-2653-4ee5-b7d1-c1296c94bad2"
      },
      "source": [
        "# Run with template"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KGPy0HmHYTJQ",
      "metadata": {
        "id": "KGPy0HmHYTJQ"
      },
      "source": [
        "### Method 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3de2e7e-255e-43e2-bf42-28441599517e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3de2e7e-255e-43e2-bf42-28441599517e",
        "outputId": "23b4a6f5-da17-440f-dfa1-497ccc5b96b2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 Jul 2024\n",
            "\n",
            "You are a helpful developer assistant, answer all the questions correctly and concisely.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "機器學習的定義？<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "機器學習（Machine Learning）是人工智能的一個子領域，指的是計算機能夠通過從數據中學習和改進的能力，來進行模式識別、預測和決策。它的主要目的是使計算機能夠自動地從數據中獲得知識和技能，從而實現特定任務的自動化。\n",
            "\n",
            "機器學習的核心思想是讓計算機能夠從數據中學習和改進，通過以下幾個步驟：\n",
            "\n",
            "1. 資料收集：收集相關數據和特徵。\n",
            "2. 模型建構：建立機器學習模型，例如決策樹、隨機森林等。\n",
            "3. 模型訓練：訓練模型，讓它能夠從數據中學習和改進。\n",
            "4. 模型評估：評估模型的性能和準確度。\n",
            "5. 模型部署：將模型部署到實際應用中。\n",
            "\n",
            "機器學習的應用範圍廣泛，包括：\n",
            "\n",
            "* 圖像識別和處理\n",
            "* 自然語言處理\n",
            "* 聽覺和語音識別\n",
            "* 預測和預測\n",
            "* 自動化決策等。<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "char_message = tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "input_ids = tokenizer(char_message, return_tensors=\"pt\").to(device)\n",
        "outputs = model.generate(**input_ids, max_length=1000)\n",
        "print(tokenizer.decode(outputs[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9oMBsAVGbq0z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oMBsAVGbq0z",
        "outputId": "2c4bfbb4-0784-4e43-dea0-e066a10125ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "機器學習（Machine Learning）是人工智能的一個子領域，指的是計算機能夠通過從數據中學習和改進的能力，來進行模式識別、預測和決策。它的主要目的是使計算機能夠自動地從數據中獲得知識和技能，從而實現特定任務的自動化。\n",
            "\n",
            "機器學習的核心思想是讓計算機能夠從數據中學習和改進，通過以下幾個步驟：\n",
            "\n",
            "1. 資料收集：收集相關數據和特徵。\n",
            "2. 模型建構：建立機器學習模型，例如決策樹、隨機森林等。\n",
            "3. 模型訓練：訓練模型，讓它能夠從數據中學習和改進。\n",
            "4. 模型評估：評估模型的性能和準確度。\n",
            "5. 模型部署：將模型部署到實際應用中。\n",
            "\n",
            "機器學習的應用範圍廣泛，包括：\n",
            "\n",
            "* 圖像識別和處理\n",
            "* 自然語言處理\n",
            "* 聽覺和語音識別\n",
            "* 預測和預測\n",
            "* 自動化決策等。\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(outputs[0][input_ids['input_ids'].shape[1]:-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cvGfYu2NYYkZ",
      "metadata": {
        "id": "cvGfYu2NYYkZ"
      },
      "source": [
        "### Method 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff74c86a-a1ff-47b1-b855-f4c6bbc3634e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff74c86a-a1ff-47b1-b855-f4c6bbc3634e",
        "outputId": "eb1dadab-b870-43d0-a309-4d2119dc2162"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 Jul 2024\n",
            "\n",
            "You are a helpful developer assistant, answer all the questions correctly and concisely.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "機器學習的定義？<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "機器學習（Machine Learning）是指使用電腦算法和數據來訓練模型，使其能夠從數據中學習和改善其性能，從而能夠對未知的輸入進行預測或決策。它是一種人工智慧的子領域，旨在讓電腦能夠通過數據學習和改進自己的能力，無需明確程式碼。<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "input_ids = tokenizer.apply_chat_template(messages, return_dict=True, return_tensors=\"pt\").to(device)\n",
        "outputs = model.generate(**input_ids, max_length=500)\n",
        "print(tokenizer.decode(outputs[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_zMz7zmBcwHY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zMz7zmBcwHY",
        "outputId": "07eb177f-293a-4aaa-9557-13ef6df50651"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "機器學習（Machine Learning）是指使用電腦算法和數據來訓練模型，使其能夠從數據中學習和改善其性能，從而能夠對未知的輸入進行預測或決策。它是一種人工智慧的子領域，旨在讓電腦能夠通過數據學習和改進自己的能力，無需明確程式碼。\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(outputs[0][input_ids['input_ids'].shape[1]:-1]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d1bf8ba370343898c7ef34962a76963": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91aae0f4c5a044008b91395a6dfa4bbe",
            "placeholder": "​",
            "style": "IPY_MODEL_fe0e7cef1d03495a9330a1b026e6c65d",
            "value": " 4/4 [01:09&lt;00:00, 16.17s/it]"
          }
        },
        "34067bb79c5e4a43b51388e02d59b8e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66ca366a0c394660bf8a5cf14baf7da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "719f955b0e374c339795577c8292978c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8453b1b248564463b0c0f359ca79b002": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34067bb79c5e4a43b51388e02d59b8e9",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66ca366a0c394660bf8a5cf14baf7da5",
            "value": 4
          }
        },
        "91aae0f4c5a044008b91395a6dfa4bbe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d66c35b4e5a4e55b8ba6cce4681e728": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc5836cd1a014b1091eb9bdcc4fb8789",
              "IPY_MODEL_8453b1b248564463b0c0f359ca79b002",
              "IPY_MODEL_0d1bf8ba370343898c7ef34962a76963"
            ],
            "layout": "IPY_MODEL_efdd824e788642efbf8e18c4f7ed319f"
          }
        },
        "bcae8a9f725848688c917a0e71eeba5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc5836cd1a014b1091eb9bdcc4fb8789": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcae8a9f725848688c917a0e71eeba5d",
            "placeholder": "​",
            "style": "IPY_MODEL_719f955b0e374c339795577c8292978c",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "efdd824e788642efbf8e18c4f7ed319f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe0e7cef1d03495a9330a1b026e6c65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}